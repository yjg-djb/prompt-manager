# 场景：Ollama模型调用代码生成（多语言）

## 核心用途

生成指定编程语言调用Ollama模型的完整代码，含参数配置、响应处理等。

---

## 提示词模板

### 调用需求

- **模型信息**：[指定要调用的模型]
  - 示例：`llama3:8b`、`qwen:7b`、`gemma:2b`

- **核心功能**：[描述要实现的功能]
  - 示例：文本生成、文本总结、翻译（中文→英文）、问答（基于给定上下文）

- **编程语言**：[指定开发语言]
  - 示例：Python、JavaScript、Java、Go、Rust

- **调用方式**：[说明调用模式]
  - 本地Ollama服务调用 / 远程Ollama服务调用

- **服务地址**：[填写服务地址]
  - 示例：`localhost:11434`、`http://192.168.1.100:11434`

### 参数要求

- **生成参数**：[指定模型参数]
  - 示例：`temperature=0.6`、`max_tokens=1000`、`top_p=0.9`

- **响应要求**：[说明响应处理需求]
  - 示例：流式响应/非流式响应、返回结果含模型名称、生成耗时

- **额外约束**：[其他要求]
  - 示例：需处理网络异常、添加请求超时控制（30s）、错误信息友好提示

### 期望输出要求

1. **完整可运行代码**（含依赖导入、参数定义、调用逻辑、响应处理）
2. **依赖安装命令**（如pip安装命令）
3. **代码注释**（关键步骤、参数说明）
4. **测试方法**（含测试输入、预期输出）
5. **常见错误处理方案**（如服务未启动、网络中断、模型不存在）

### 输出格式约束

- 代码用对应语言的代码块标记（如 ```python）
- 依赖安装命令单独列出
- 注释清晰
- **错误处理部分**用加粗标注

---

## 使用示例

```
我需要生成调用Ollama模型的Python代码。

【调用需求】
- 模型信息：qwen:7b
- 核心功能：文本翻译（中文→英文）
- 编程语言：Python
- 调用方式：本地Ollama服务调用
- 服务地址：localhost:11434

【参数要求】
- 生成参数：temperature=0.3、max_tokens=500
- 响应要求：非流式响应，返回翻译结果和耗时
- 额外约束：添加30s超时控制、友好的错误提示

请提供完整的Python代码，包含依赖安装、代码实现、测试方法和错误处理。
```
